{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"pgraf","text":"<p>pgraf turns PostgreSQL into a lightning fast property graph engine with vector search capabilities, designed for use in AI agents and applications.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Typed Models: Strong typing with Pydantic models for nodes, edges, and content</li> <li>Vector Search: Built-in support for embeddings and semantic search</li> <li>Property Graph: Full property graph capabilities with typed nodes and labeled edges</li> <li>Asynchronous API: Modern async/await API for high-performance applications</li> <li>PostgreSQL Backend: Uses PostgreSQL's power for reliability and scalability</li> </ul>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install pgraf\n</code></pre>"},{"location":"#database-setup","title":"Database Setup","text":"<p>Ensure pgvector is installed.</p> <p>DDL is located in schema/pgraf.sql</p> <pre><code>psql -f schema/pgraf.sql\n</code></pre>"},{"location":"#requirements","title":"Requirements","text":"<ul> <li>Python 3.12+</li> <li>PostgreSQL 14+</li> </ul>"},{"location":"contributing/","title":"Contributing","text":"<p>Contributions to pgraf are welcome! Here's how to get started.</p>"},{"location":"contributing/#development-setup","title":"Development Setup","text":"<ol> <li>Fork the repository on GitHub</li> <li>Clone your fork locally:</li> </ol> <pre><code>git clone https://github.com/your-username/pgraf.git\ncd pgraf\n</code></pre> <ol> <li>Install development dependencies:</li> </ol> <pre><code>pip install -e \".[dev]\"\n</code></pre> <ol> <li>Set up pre-commit hooks:</li> </ol> <pre><code>pre-commit install\n</code></pre> <ol> <li>Start the development database:</li> </ol> <pre><code>docker-compose up -d\n</code></pre>"},{"location":"contributing/#development-workflow","title":"Development Workflow","text":"<ol> <li>Create a branch for your feature:</li> </ol> <pre><code>git checkout -b feature-name\n</code></pre> <ol> <li>Make your changes</li> <li>Run tests:</li> </ol> <pre><code>pytest\n</code></pre> <ol> <li>Run type checking:</li> </ol> <pre><code>mypy pgraf tests\n</code></pre> <ol> <li>Run linting:</li> </ol> <pre><code>ruff check .\n</code></pre> <ol> <li>Format code:</li> </ol> <pre><code>ruff format .\n</code></pre> <ol> <li>Commit your changes</li> <li>Push your branch and create a pull request</li> </ol>"},{"location":"contributing/#code-style-guidelines","title":"Code Style Guidelines","text":"<ul> <li>Follow PEP-8 with 79 character line length (enforced by ruff)</li> <li>Use single quotes for strings, double quotes for docstrings</li> <li>Write Google-style docstrings</li> <li>Include type annotations for all functions and methods</li> <li>Run formatting with ruff before committing</li> </ul>"},{"location":"contributing/#testing","title":"Testing","text":"<ul> <li>Write unit tests for all new functionality</li> <li>Ensure all tests pass before submitting a pull request</li> <li>Maintain test coverage above 90%</li> </ul>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.12+</li> <li>PostgreSQL 14+</li> <li>pgvector extension for PostgreSQL</li> </ul>"},{"location":"installation/#installing-pgraf","title":"Installing pgraf","text":"<p>Install pgraf using pip:</p> <pre><code>pip install pgraf\n</code></pre> <p>For development, you can install the development dependencies:</p> <pre><code>pip install -e \".[dev]\"\n</code></pre> <p>For building documentation:</p> <pre><code>pip install -e \".[docs]\"\n</code></pre>"},{"location":"installation/#database-setup","title":"Database Setup","text":"<ol> <li>Ensure pgvector is installed in your PostgreSQL instance</li> </ol> <p>Follow the installation instructions at: https://github.com/pgvector/pgvector</p> <ol> <li>Create a database for pgraf:</li> </ol> <pre><code>createdb pgraf\n</code></pre> <ol> <li>Apply the schema:</li> </ol> <pre><code>psql -d pgraf -f schema/pgraf.sql\n</code></pre>"},{"location":"installation/#docker-setup","title":"Docker Setup","text":"<p>A Docker Compose configuration is included for easier development:</p> <pre><code>docker-compose up -d\n</code></pre> <p>This will start a PostgreSQL instance with pgvector pre-installed and the pgraf schema applied.</p>"},{"location":"license/","title":"License","text":"<p>pgraf is licensed under the BSD 3-Clause License.</p> <pre><code>Copyright (c) 2025, Gavin M. Roy, AWeber\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n1. Redistributions of source code must retain the above copyright notice, this\n   list of conditions and the following disclaimer.\n\n2. Redistributions in binary form must reproduce the above copyright notice,\n   this list of conditions and the following disclaimer in the documentation\n   and/or other materials provided with the distribution.\n\n3. Neither the name of the copyright holder nor the names of its\n   contributors may be used to endorse or promote products derived from\n   this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n</code></pre>"},{"location":"overview/","title":"Overview","text":"<p>pgraf provides a high-performance property graph database implementation built on top of PostgreSQL, with specific optimizations for AI agent use cases.</p>"},{"location":"overview/#what-is-a-property-graph","title":"What is a Property Graph?","text":"<p>A property graph is a graph data structure that consists of:</p> <ul> <li>Nodes: Entities with properties and labels</li> <li>Edges: Relationships between nodes with labels and properties</li> <li>Properties: Key-value pairs attached to both nodes and edges</li> <li>Labels: Categorization tags for nodes and edges</li> </ul> <p>pgraf enhances this model with:</p> <ul> <li>Strong typing via Pydantic models</li> <li>Vector embeddings for semantic search</li> <li>Full-text content storage and retrieval</li> <li>Asynchronous API for high concurrency</li> </ul>"},{"location":"overview/#use-cases","title":"Use Cases","text":"<p>pgraf is particularly well-suited for:</p> <ul> <li>AI agent knowledge graphs</li> <li>Semantic search applications</li> <li>Document networks with relationships</li> <li>Complex data modeling with typed relationships</li> <li>Applications requiring both graph and vector search capabilities</li> </ul>"},{"location":"overview/#architecture","title":"Architecture","text":"<p>pgraf uses:</p> <ul> <li>PostgreSQL as the storage backend</li> <li>pgvector for vector operations</li> <li>Pydantic for model validation</li> <li>Async Python for high-performance operations</li> </ul> <p>The architecture consists of several key components:</p> <ul> <li>Graph Engine: Core graph operations (nodes, edges, traversals)</li> <li>Vector Search: Embedding management and similarity search</li> <li>Type System: Strongly-typed models for graph elements</li> <li>Query Layer: Composable query building system</li> </ul>"},{"location":"usage/","title":"Usage","text":""},{"location":"usage/#basic-usage","title":"Basic Usage","text":""},{"location":"usage/#initializing-pgraf","title":"Initializing pgraf","text":"<pre><code>import asyncio\nfrom pgraf import graph\n\nasync def main():\n    # Initialize the graph with PostgreSQL connection\n    pgraf = graph.PGraf(url=\"postgresql://postgres:postgres@localhost:5432/pgraf\")\n\n    try:\n        # Your code here\n        pass\n    finally:\n        # Always close connections\n        await pgraf.aclose()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"usage/#working-with-nodes","title":"Working with Nodes","text":"<p>Creating nodes:</p> <pre><code># Add a simple node\nperson = await pgraf.add_node(\n    labels=[\"person\"],\n    properties={\"name\": \"Alice\", \"age\": 30}\n)\n\n# Add a node with content and vector embeddings\ndocument = await pgraf.add_node(\n    labels=[\"document\"],\n    properties={\n        \"tags\": [\"example\"],\n        \"title\": \"Sample Document\",\n        \"url\": \"https://www.google.com\"\n    },\n    mimetype=\"text/plain\",\n    content=\"This is a sample document that will be embedded in vector space.\"\n)\n</code></pre> <p>Querying nodes:</p> <pre><code># Retrieve nodes by label and properties\nall_people = []\nasync for node in pgraf.get_nodes(\n    labels=[\"person\"],\n    properties={\"name\": \"Alice\"}\n):\n    all_people.append(node)\n\n# Get a specific node by ID\nnode = await pgraf.get_node(node_id)\n</code></pre>"},{"location":"usage/#working-with-edges","title":"Working with Edges","text":"<p>Creating edges:</p> <pre><code># Create a relationship between nodes\nawait pgraf.add_edge(\n    source=person.id,\n    target=document.id,\n    labels=[\"CREATED\"],\n    properties={\"timestamp\": \"2023-01-01\"}\n)\n</code></pre> <p>Querying edges:</p> <pre><code># Get edges between nodes\nedges = await pgraf.get_edges(\n    source=person.id,\n    target=document.id,\n    labels=[\"CREATED\"]\n)\n</code></pre>"},{"location":"usage/#graph-traversal","title":"Graph Traversal","text":"<p>Traversing the graph:</p> <pre><code># Traverse the graph\ntraversal_results = await pgraf.traverse(\n    start_node=person.id,\n    edge_labels=[\"CREATED\"],\n    direction=\"outgoing\",\n    max_depth=2\n)\n\n# Print traversal results\nfor node, edge in traversal_results:\n    print(f\"Node: {node.type} {node.id}\")\n    if edge:\n        print(f\"  via edge: {edge.label}\")\n</code></pre>"},{"location":"usage/#vector-search","title":"Vector Search","text":"<p>Searching by vector similarity:</p> <pre><code># Search for semantically similar content\nresults = await pgraf.search(\n    query=\"What are property graphs?\",\n    limit=5\n)\n\nfor result in results:\n    print(f\"Score: {result.score}, Node: {result.node.id}\")\n    print(f\"Content: {result.node.content[:100]}...\")\n</code></pre>"},{"location":"api/embeddings/","title":"Embeddings","text":""},{"location":"api/embeddings/#pgraf.embeddings","title":"<code>pgraf.embeddings</code>","text":""},{"location":"api/embeddings/#pgraf.embeddings.Engine","title":"<code>Engine</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Enum for the available embedding engines</p> Source code in <code>pgraf/embeddings.py</code> <pre><code>class Engine(enum.Enum):\n    \"\"\"Enum for the available embedding engines\"\"\"\n\n    HUGGING_FACE = 'hugging-face'\n    OPENAI = 'openai'\n</code></pre>"},{"location":"api/embeddings/#pgraf.embeddings.HuggingFace","title":"<code>HuggingFace</code>","text":"<p>Handles the generation of vector embeddings for text content.</p> <p>This class provides functionality to convert text into vector embeddings using sentence transformers. It handles chunking of text to ensure optimal embedding generation.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str | None</code> <p>The sentence transformer model to use for embeddings</p> <code>DEFAULT_HUGGING_FACE_MODEL</code> Source code in <code>pgraf/embeddings.py</code> <pre><code>class HuggingFace:\n    \"\"\"Handles the generation of vector embeddings for text content.\n\n    This class provides functionality to convert text into vector embeddings\n    using sentence transformers. It handles chunking of text to ensure\n    optimal embedding generation.\n\n    Args:\n        model: The sentence transformer model to use for embeddings\n    \"\"\"\n\n    def __init__(self, model: str | None = DEFAULT_HUGGING_FACE_MODEL) -&gt; None:\n        \"\"\"Initialize the embeddings generator with the specified model.\n\n        Args:\n            model: The sentence transformer model to use\n                (defaults to 'all-MiniLM-L6-v2')\n        \"\"\"\n        self.transformer = sentence_transformers.SentenceTransformer(\n            model or DEFAULT_HUGGING_FACE_MODEL\n        )\n\n    def get(self, value: str) -&gt; list[numpy.ndarray]:\n        \"\"\"Generate embeddings for the provided text value.\n\n        The text is automatically chunked into manageable pieces\n        using sentence boundaries and maximum word count.\n\n        Args:\n            value: The text to generate embeddings for\n\n        Returns:\n            A list of numpy arrays containing the embeddings for each chunk\n        \"\"\"\n        embeddings: list[numpy.ndarray] = []\n        for chunk in _chunk_text(value):\n            result: numpy.ndarray = self.transformer.encode(\n                chunk, convert_to_numpy=True, convert_to_tensor=False\n            )\n            embeddings.append(result)\n        return embeddings\n</code></pre>"},{"location":"api/embeddings/#pgraf.embeddings.HuggingFace.__init__","title":"<code>__init__(model=DEFAULT_HUGGING_FACE_MODEL)</code>","text":"<p>Initialize the embeddings generator with the specified model.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str | None</code> <p>The sentence transformer model to use (defaults to 'all-MiniLM-L6-v2')</p> <code>DEFAULT_HUGGING_FACE_MODEL</code> Source code in <code>pgraf/embeddings.py</code> <pre><code>def __init__(self, model: str | None = DEFAULT_HUGGING_FACE_MODEL) -&gt; None:\n    \"\"\"Initialize the embeddings generator with the specified model.\n\n    Args:\n        model: The sentence transformer model to use\n            (defaults to 'all-MiniLM-L6-v2')\n    \"\"\"\n    self.transformer = sentence_transformers.SentenceTransformer(\n        model or DEFAULT_HUGGING_FACE_MODEL\n    )\n</code></pre>"},{"location":"api/embeddings/#pgraf.embeddings.HuggingFace.get","title":"<code>get(value)</code>","text":"<p>Generate embeddings for the provided text value.</p> <p>The text is automatically chunked into manageable pieces using sentence boundaries and maximum word count.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>The text to generate embeddings for</p> required <p>Returns:</p> Type Description <code>list[ndarray]</code> <p>A list of numpy arrays containing the embeddings for each chunk</p> Source code in <code>pgraf/embeddings.py</code> <pre><code>def get(self, value: str) -&gt; list[numpy.ndarray]:\n    \"\"\"Generate embeddings for the provided text value.\n\n    The text is automatically chunked into manageable pieces\n    using sentence boundaries and maximum word count.\n\n    Args:\n        value: The text to generate embeddings for\n\n    Returns:\n        A list of numpy arrays containing the embeddings for each chunk\n    \"\"\"\n    embeddings: list[numpy.ndarray] = []\n    for chunk in _chunk_text(value):\n        result: numpy.ndarray = self.transformer.encode(\n            chunk, convert_to_numpy=True, convert_to_tensor=False\n        )\n        embeddings.append(result)\n    return embeddings\n</code></pre>"},{"location":"api/embeddings/#pgraf.embeddings.OpenAI","title":"<code>OpenAI</code>","text":"<p>Handles the generation of vector embeddings for text content using the OpenAI client</p> Source code in <code>pgraf/embeddings.py</code> <pre><code>class OpenAI:\n    \"\"\"Handles the generation of vector embeddings for text content using the\n    OpenAI client\n    \"\"\"\n\n    def __init__(\n        self,\n        model: str | None = DEFAULT_OPENAI_MODEL,\n        api_key: str | None = None,\n    ) -&gt; None:\n        \"\"\"Initialize the embeddings generator with the specified model.\"\"\"\n        self.client = openai.OpenAI(api_key=api_key)\n        self.model = model or DEFAULT_OPENAI_MODEL\n\n    def get(self, value: str) -&gt; list[numpy.ndarray]:\n        \"\"\"Generate embeddings for the provided text value.\n\n        The text is automatically chunked into manageable pieces\n        using sentence boundaries and maximum word count.\n\n        Args:\n            value: The text to generate embeddings for\n\n        Returns:\n            A list of numpy arrays containing the embeddings for each chunk\n        \"\"\"\n        embeddings: list[numpy.ndarray] = []\n        for chunk in _chunk_text(value):\n            response = self.client.embeddings.create(\n                input=chunk, model=self.model\n            )\n            embeddings.append(numpy.array(response.data[0].embedding))\n        return embeddings\n</code></pre>"},{"location":"api/embeddings/#pgraf.embeddings.OpenAI.__init__","title":"<code>__init__(model=DEFAULT_OPENAI_MODEL, api_key=None)</code>","text":"<p>Initialize the embeddings generator with the specified model.</p> Source code in <code>pgraf/embeddings.py</code> <pre><code>def __init__(\n    self,\n    model: str | None = DEFAULT_OPENAI_MODEL,\n    api_key: str | None = None,\n) -&gt; None:\n    \"\"\"Initialize the embeddings generator with the specified model.\"\"\"\n    self.client = openai.OpenAI(api_key=api_key)\n    self.model = model or DEFAULT_OPENAI_MODEL\n</code></pre>"},{"location":"api/embeddings/#pgraf.embeddings.OpenAI.get","title":"<code>get(value)</code>","text":"<p>Generate embeddings for the provided text value.</p> <p>The text is automatically chunked into manageable pieces using sentence boundaries and maximum word count.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>The text to generate embeddings for</p> required <p>Returns:</p> Type Description <code>list[ndarray]</code> <p>A list of numpy arrays containing the embeddings for each chunk</p> Source code in <code>pgraf/embeddings.py</code> <pre><code>def get(self, value: str) -&gt; list[numpy.ndarray]:\n    \"\"\"Generate embeddings for the provided text value.\n\n    The text is automatically chunked into manageable pieces\n    using sentence boundaries and maximum word count.\n\n    Args:\n        value: The text to generate embeddings for\n\n    Returns:\n        A list of numpy arrays containing the embeddings for each chunk\n    \"\"\"\n    embeddings: list[numpy.ndarray] = []\n    for chunk in _chunk_text(value):\n        response = self.client.embeddings.create(\n            input=chunk, model=self.model\n        )\n        embeddings.append(numpy.array(response.data[0].embedding))\n    return embeddings\n</code></pre>"},{"location":"api/errors/","title":"Errors","text":""},{"location":"api/errors/#pgraf.errors","title":"<code>pgraf.errors</code>","text":""},{"location":"api/errors/#pgraf.errors.DatabaseError","title":"<code>DatabaseError</code>","text":"<p>               Bases: <code>DatabaseError</code></p> <p>Raised when there is an error querying the database.</p> <p>This exception is the base class for all database-related errors in pgraf. It inherits from psycopg.DatabaseError and may contain additional context specific to pgraf operations.</p> <p>Examples:</p> <pre><code>try:\n    await pgraf.add_node(\n        labels=['person']\n    )\nexcept DatabaseError as error:\n    print(\n        f'Database error occurred: {error}'\n    )\n</code></pre> Source code in <code>pgraf/errors.py</code> <pre><code>class DatabaseError(psycopg.DatabaseError):\n    \"\"\"Raised when there is an error querying the database.\n\n    This exception is the base class for all database-related errors in pgraf.\n    It inherits from psycopg.DatabaseError and may contain additional context\n    specific to pgraf operations.\n\n    Examples:\n        ```python\n        try:\n            await pgraf.add_node(\n                labels=['person']\n            )\n        except DatabaseError as error:\n            print(\n                f'Database error occurred: {error}'\n            )\n        ```\n    \"\"\"\n\n    ...\n</code></pre>"},{"location":"api/graph/","title":"Graph","text":""},{"location":"api/graph/#pgraf.graph","title":"<code>pgraf.graph</code>","text":""},{"location":"api/graph/#pgraf.graph.PGraf","title":"<code>PGraf</code>","text":"<p>Manage and Search the Property Graph.</p> <p>The PGraf class is the main entry point for interacting with the graph database. It provides methods for adding nodes and edges, querying, traversing the graph, and performing vector similarity searches.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>PostgresDsn</code> <p>PostgreSQL connection URL</p> required <code>pool_min_size</code> <code>int</code> <p>Minimum number of connections in the pool</p> <code>1</code> <code>pool_max_size</code> <code>int</code> <p>Maximum number of connections in the pool</p> <code>10</code> Source code in <code>pgraf/graph.py</code> <pre><code>class PGraf:\n    \"\"\"Manage and Search the Property Graph.\n\n    The PGraf class is the main entry point for interacting with the graph\n    database. It provides methods for adding nodes and edges, querying,\n    traversing the graph, and performing vector similarity searches.\n\n    Args:\n        url: PostgreSQL connection URL\n        pool_min_size: Minimum number of connections in the pool\n        pool_max_size: Maximum number of connections in the pool\n    \"\"\"\n\n    def __init__(\n        self,\n        url: pydantic.PostgresDsn,\n        pool_min_size: int = 1,\n        pool_max_size: int = 10,\n    ) -&gt; None:\n        \"\"\"Initialize a new PGraf instance.\n\n        Args:\n            url: PostgreSQL connection URL\n            pool_min_size: Minimum number of connections in the pool\n            pool_max_size: Maximum number of connections in the pool\n        \"\"\"\n        self._embeddings = embeddings.Embeddings()\n        self._postgres = postgres.Postgres(url, pool_min_size, pool_max_size)\n\n    async def initialize(self) -&gt; None:\n        \"\"\"Ensure the database is connected and ready to go.\"\"\"\n        await self._postgres.initialize()\n\n    async def aclose(self) -&gt; None:\n        \"\"\"Close the Postgres connection pool.\"\"\"\n        await self._postgres.aclose()\n\n    async def add_node(\n        self,\n        labels: list[str],\n        properties: dict | None = None,\n        created_at: datetime.datetime | None = None,\n        modified_at: datetime.datetime | None = None,\n        mimetype: str | None = None,\n        content: str | None = None,\n    ) -&gt; models.Node:\n        \"\"\"Add a node to the graph\"\"\"\n        value = models.Node(\n            labels=labels,\n            properties=properties or {},\n            mimetype=mimetype,\n            content=content,\n        )\n        if created_at is not None:\n            value.created_at = created_at\n        if modified_at is not None:\n            value.modified_at = modified_at\n        async with self._postgres.callproc(\n            'pgraf.add_node', value, models.Node\n        ) as cursor:\n            result: models.Node = await cursor.fetchone()  # type: ignore\n        if value.content is not None:\n            await self._add_embeddings(value.id, value.content)\n        return result\n\n    async def delete_node(self, node_id: uuid.UUID) -&gt; bool:\n        \"\"\"Retrieve a node by ID\"\"\"\n        async with self._postgres.callproc(\n            'pgraf.delete_node', {'id': node_id}\n        ) as cursor:\n            result: dict[str, int] = await cursor.fetchone()  # type: ignore\n            return result['count'] == 1\n\n    async def get_node(self, node_id: uuid.UUID | None) -&gt; models.Node | None:\n        \"\"\"Retrieve a node by ID\"\"\"\n        async with self._postgres.callproc(\n            'pgraf.get_node', {'id': node_id}, models.Node\n        ) as cursor:\n            if cursor.rowcount == 1:\n                return await cursor.fetchone()  # type: ignore\n            return None\n\n    async def get_node_labels(self) -&gt; list[str]:\n        \"\"\"Retrieve all of the node types in the graph\"\"\"\n        return await self._get_labels('nodes')\n\n    async def get_node_properties(self) -&gt; list[str]:\n        \"\"\"Retrieve the distincty property names across all nodes\"\"\"\n        return await self._get_properties('nodes')\n\n    async def get_nodes(\n        self, labels: list[str] | None = None, properties: dict | None = None\n    ) -&gt; typing.AsyncGenerator[models.Node, None]:\n        \"\"\"Get all nodes matching the criteria\"\"\"\n        statement, parameters = self._build_statement(\n            queries.GET_NODES, labels, properties\n        )\n        async with self._postgres.execute(\n            statement, parameters, models.Node\n        ) as cursor:\n            async for row in cursor:\n                yield models.Node.model_validate(row)\n\n    async def update_node(self, node: models.Node) -&gt; models.Node:\n        \"\"\"Update a node\"\"\"\n        async with self._postgres.callproc(\n            'pgraf.update_node', node, models.Node\n        ) as cursor:\n            result: models.Node = await cursor.fetchone()  # type: ignore\n        if result.content is not None:\n            await self._add_embeddings(result.id, result.content)\n        return result\n\n    async def add_edge(\n        self,\n        source: uuid.UUID,\n        target: uuid.UUID,\n        labels: list[str] | None = None,\n        properties: dict | None = None,\n    ) -&gt; models.Edge:\n        \"\"\"Add an edge, linking two nodes in the graph\"\"\"\n        value = models.Edge(\n            source=source,\n            target=target,\n            labels=labels or [],\n            properties=properties or {},\n        )\n        async with self._postgres.callproc(\n            'pgraf.add_edge', value, models.Edge\n        ) as cursor:\n            return await cursor.fetchone()  # type: ignore\n\n    async def delete_edge(self, source: uuid.UUID, target: uuid.UUID) -&gt; bool:\n        \"\"\"Remove an edge, severing the relationship between two nodes\n\n        Note: This is a directional operation. It only removes the edge going\n        from source to target, not from target to source.\n        \"\"\"\n        async with self._postgres.callproc(\n            'pgraf.delete_edge', {'source': source, 'target': target}\n        ) as cursor:\n            result: dict[str, int] = await cursor.fetchone()  # type: ignore\n            return result['count'] == 1\n\n    async def get_edge(\n        self, source: uuid.UUID, target: uuid.UUID\n    ) -&gt; models.Edge | None:\n        \"\"\"Retrieve an edge from source to target\n\n        Note: This is a directional operation. It only retrieves the edge going\n        from source to target, not from target to source.\n        \"\"\"\n        async with self._postgres.callproc(\n            'pgraf.get_edge', {'source': source, 'target': target}, models.Edge\n        ) as cursor:\n            if cursor.rowcount == 0:\n                return None\n            return await cursor.fetchone()  # type: ignore\n\n    async def get_edges(\n        self, labels: list[str] | None = None, properties: dict | None = None\n    ) -&gt; typing.AsyncGenerator[models.Edge, None]:\n        \"\"\"Get edges by criteria\"\"\"\n        statement, parameters = self._build_statement(\n            queries.GET_EDGES, labels, properties\n        )\n        async with self._postgres.execute(\n            statement, parameters, models.Edge\n        ) as cursor:\n            async for row in cursor:\n                yield models.Edge.model_validate(row)\n\n    async def get_edge_labels(self) -&gt; list[str]:\n        \"\"\"Retrieve all of the edge labels in the graph\"\"\"\n        return await self._get_labels('edges')\n\n    async def get_edge_properties(self) -&gt; list[str]:\n        \"\"\"Retrieve all of the edge property names in the graph\"\"\"\n        return await self._get_properties('edges')\n\n    async def update_edge(self, edge: models.Edge) -&gt; models.Edge:\n        \"\"\"Update an edge\"\"\"\n        async with self._postgres.callproc(\n            'pgraf.update_edge', edge, models.Edge\n        ) as cursor:\n            return await cursor.fetchone()  # type: ignore\n\n    async def search(\n        self,\n        query: str,\n        labels: list[str] | None = None,\n        properties: dict | None = None,\n        similarity_threshold: float = 0.1,\n        limit: int = 10,\n        offset: int = 0,\n    ) -&gt; list[models.SearchResult]:\n        \"\"\"Search the content nodes in the graph, optionally filtering by\n        properties, node types, and the edges labels.\n\n        \"\"\"\n        vector = self._embeddings.get(query)\n        if len(vector) &gt; 1:\n            LOGGER.warning(\n                'Search text embeddings returned %i vector arrays', len(vector)\n            )\n        async with self._postgres.callproc(\n            'pgraf.search',\n            {\n                'query': query,\n                'labels': labels,\n                'properties': json.Jsonb(properties) if properties else None,\n                'embeddings': vector[0],\n                'similarity': similarity_threshold,\n                'limit': limit,\n                'offset': offset,\n            },\n            models.SearchResult,\n        ) as cursor:\n            results: list[models.SearchResult] = await cursor.fetchall()  # type: ignore\n            return results\n\n    async def traverse(\n        self,\n        start_node: uuid.UUID,\n        node_labels: list[str] | None = None,\n        edge_labels: list[str] | None = None,\n        direction: str = 'outgoing',\n        max_depth: int = 5,\n        limit: int = 25,\n    ) -&gt; list[tuple[models.Node, models.Edge | None]]:\n        \"\"\"Traverse the graph from a starting node\"\"\"\n        results: list[tuple[models.Node, models.Edge | None]] = []\n        visited_nodes = set()  # Track visited nodes to avoid duplicates\n\n        # Recursive helper function to implement depth-first traversal\n        async def traverse_recursive(node_id, current_depth=0, path_edge=None):\n            # Check the limit\n            if len(results) &gt;= limit:\n                return\n\n            # Check max depth\n            if current_depth &gt; max_depth:\n                return\n\n            # Check if we've visited this node\n            if node_id in visited_nodes:\n                return\n\n            # Mark this node as visited\n            visited_nodes.add(node_id)\n\n            # Get the current node\n            current_node = await self.get_node(node_id)\n            if not current_node:\n                return\n\n            # Apply node label filtering\n            if node_labels and not any(\n                label in current_node.labels for label in node_labels\n            ):\n                # Only filter at depth &gt; 0 to ensure starting node is included\n                if current_depth &gt; 0:\n                    return\n\n            # Add this node to results\n            results.append((current_node, path_edge))\n\n            if current_depth &gt;= max_depth:\n                return\n\n            # Build SQL query based on direction\n            if direction == 'outgoing':\n                query = sql.SQL(\n                    'SELECT * FROM pgraf.edges WHERE source = %(node_id)s'\n                )\n            elif direction == 'incoming':\n                query = sql.SQL(\n                    'SELECT * FROM pgraf.edges WHERE target = %(node_id)s'\n                )\n            else:  # both\n                query = sql.SQL(\n                    \"\"\"\\\n                    SELECT *\n                      FROM pgraf.edges\n                     WHERE source = %(node_id)s\n                        OR target = %(node_id)s\n                    \"\"\"\n                )\n\n            # Get all edges connected to this node\n            async with self._postgres.execute(\n                query, {'node_id': node_id}\n            ) as cursor:\n                edges = await cursor.fetchall()\n\n                # Process each edge\n                for edge_row in edges:\n                    # Skip edges that don't match filter criteria\n                    if edge_labels and not any(\n                        label in edge_row['labels'] for label in edge_labels\n                    ):\n                        continue\n\n                    # Create the edge model\n                    edge = models.Edge(\n                        source=edge_row['source'],\n                        target=edge_row['target'],\n                        labels=edge_row['labels'],\n                        properties=edge_row['properties'],\n                    )\n\n                    # Determine the next node ID based on direction\n                    next_id = edge_row['target']\n                    if direction == 'incoming' or (\n                        direction == 'both' and edge_row['target'] == node_id\n                    ):\n                        next_id = edge_row['source']\n\n                    # Skip if it's the current node\n                    if next_id == node_id:\n                        continue\n\n                    # Recursively traverse\n                    await traverse_recursive(next_id, current_depth + 1, edge)\n\n                    # Check if limit reached\n                    if len(results) &gt;= limit:\n                        return\n\n        await traverse_recursive(start_node)\n        LOGGER.debug(\n            'Traverse results: %s items, visited %s nodes',\n            len(results),\n            len(visited_nodes),\n        )\n        return results\n\n    @staticmethod\n    def _build_statement(\n        select: str,\n        labels: list[str] | None = None,\n        properties: dict | None = None,\n    ) -&gt; tuple[sql.Composable, dict[str, typing.Any]]:\n        \"\"\"Generate the SQL for get_edges and get_nodes\"\"\"\n        parameters: dict[str, typing.Any] = {}\n        statement: list[str | sql.Composable] = [\n            sql.SQL(select) + sql.SQL(' ')  # type: ignore\n        ]\n        if not labels and not properties:\n            return sql.Composed(statement), parameters\n        where: list[sql.Composable] = []\n        if labels:\n            parameters['labels'] = labels\n            where.append(\n                sql.SQL('labels') + sql.SQL(' &amp;&amp; ') + sql.Placeholder('labels')\n            )\n        if properties:\n            props = []\n            for key, value in properties.items():\n                props.append(\n                    sql.SQL(f\"properties-&gt;&gt;'{key}'\")  # type: ignore\n                    + sql.SQL(' = ')\n                    + sql.Placeholder(f'props_{key}')\n                )\n                parameters[f'props_{key}'] = str(value)\n            if len(props) &gt; 1:\n                where.append(\n                    sql.SQL('(') + sql.SQL(' OR ').join(props) + sql.SQL(')')\n                )\n            else:\n                where.append(props[0])\n        if where:\n            statement.append(sql.SQL('WHERE '))\n            statement.append(sql.SQL(' AND ').join(where))\n        return sql.Composed(statement), parameters\n\n    async def _get_labels(self, table: str) -&gt; list[str]:\n        \"\"\"Dynamically construct the query to get distinct labels\"\"\"\n        query = sql.Composed(\n            [\n                sql.SQL('SELECT DISTINCT unnest(labels) AS label'),\n                sql.SQL(' FROM '),\n                sql.SQL('.').join(\n                    [sql.Identifier('pgraf'), sql.Identifier(table)]\n                ),\n                sql.SQL(' WHERE labels IS NOT NULL '),\n                sql.SQL(' ORDER BY label'),\n            ]\n        )\n        async with self._postgres.execute(query) as cursor:\n            return [row['label'] for row in await cursor.fetchall()]  # type: ignore\n\n    async def _get_properties(self, table: str) -&gt; list[str]:\n        \"\"\"Retrieve the distincty property names across all nodes\"\"\"\n        query = sql.Composed(\n            [\n                sql.SQL(\n                    'SELECT DISTINCT jsonb_object_keys(properties) AS key'\n                ),\n                sql.SQL(' FROM '),\n                sql.SQL('.').join(\n                    [sql.Identifier('pgraf'), sql.Identifier(table)]\n                ),\n                sql.SQL(' WHERE properties IS NOT NULL'),\n                sql.SQL(' ORDER BY key'),\n            ]\n        )\n        async with self._postgres.execute(query) as cursor:\n            return [row['key'] for row in await cursor.fetchall()]  # type: ignore\n\n    async def _add_embeddings(self, node_id: uuid.UUID, content: str) -&gt; None:\n        \"\"\"Chunk the content and write the embeddings\"\"\"\n        for offset, value in enumerate(self._embeddings.get(content)):\n            async with self._postgres.callproc(\n                'pgraf.add_embedding',\n                {'node': node_id, 'chunk': offset, 'value': value},\n            ) as cursor:\n                result: dict[str, bool] = await cursor.fetchone()  # type: ignore\n                if not result['success']:\n                    raise errors.DatabaseError('Failed to insert embedding')\n</code></pre>"},{"location":"api/graph/#pgraf.graph.PGraf.__init__","title":"<code>__init__(url, pool_min_size=1, pool_max_size=10)</code>","text":"<p>Initialize a new PGraf instance.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>PostgresDsn</code> <p>PostgreSQL connection URL</p> required <code>pool_min_size</code> <code>int</code> <p>Minimum number of connections in the pool</p> <code>1</code> <code>pool_max_size</code> <code>int</code> <p>Maximum number of connections in the pool</p> <code>10</code> Source code in <code>pgraf/graph.py</code> <pre><code>def __init__(\n    self,\n    url: pydantic.PostgresDsn,\n    pool_min_size: int = 1,\n    pool_max_size: int = 10,\n) -&gt; None:\n    \"\"\"Initialize a new PGraf instance.\n\n    Args:\n        url: PostgreSQL connection URL\n        pool_min_size: Minimum number of connections in the pool\n        pool_max_size: Maximum number of connections in the pool\n    \"\"\"\n    self._embeddings = embeddings.Embeddings()\n    self._postgres = postgres.Postgres(url, pool_min_size, pool_max_size)\n</code></pre>"},{"location":"api/graph/#pgraf.graph.PGraf.aclose","title":"<code>aclose()</code>  <code>async</code>","text":"<p>Close the Postgres connection pool.</p> Source code in <code>pgraf/graph.py</code> <pre><code>async def aclose(self) -&gt; None:\n    \"\"\"Close the Postgres connection pool.\"\"\"\n    await self._postgres.aclose()\n</code></pre>"},{"location":"api/graph/#pgraf.graph.PGraf.add_edge","title":"<code>add_edge(source, target, labels=None, properties=None)</code>  <code>async</code>","text":"<p>Add an edge, linking two nodes in the graph</p> Source code in <code>pgraf/graph.py</code> <pre><code>async def add_edge(\n    self,\n    source: uuid.UUID,\n    target: uuid.UUID,\n    labels: list[str] | None = None,\n    properties: dict | None = None,\n) -&gt; models.Edge:\n    \"\"\"Add an edge, linking two nodes in the graph\"\"\"\n    value = models.Edge(\n        source=source,\n        target=target,\n        labels=labels or [],\n        properties=properties or {},\n    )\n    async with self._postgres.callproc(\n        'pgraf.add_edge', value, models.Edge\n    ) as cursor:\n        return await cursor.fetchone()  # type: ignore\n</code></pre>"},{"location":"api/graph/#pgraf.graph.PGraf.add_node","title":"<code>add_node(labels, properties=None, created_at=None, modified_at=None, mimetype=None, content=None)</code>  <code>async</code>","text":"<p>Add a node to the graph</p> Source code in <code>pgraf/graph.py</code> <pre><code>async def add_node(\n    self,\n    labels: list[str],\n    properties: dict | None = None,\n    created_at: datetime.datetime | None = None,\n    modified_at: datetime.datetime | None = None,\n    mimetype: str | None = None,\n    content: str | None = None,\n) -&gt; models.Node:\n    \"\"\"Add a node to the graph\"\"\"\n    value = models.Node(\n        labels=labels,\n        properties=properties or {},\n        mimetype=mimetype,\n        content=content,\n    )\n    if created_at is not None:\n        value.created_at = created_at\n    if modified_at is not None:\n        value.modified_at = modified_at\n    async with self._postgres.callproc(\n        'pgraf.add_node', value, models.Node\n    ) as cursor:\n        result: models.Node = await cursor.fetchone()  # type: ignore\n    if value.content is not None:\n        await self._add_embeddings(value.id, value.content)\n    return result\n</code></pre>"},{"location":"api/graph/#pgraf.graph.PGraf.delete_edge","title":"<code>delete_edge(source, target)</code>  <code>async</code>","text":"<p>Remove an edge, severing the relationship between two nodes</p> <p>Note: This is a directional operation. It only removes the edge going from source to target, not from target to source.</p> Source code in <code>pgraf/graph.py</code> <pre><code>async def delete_edge(self, source: uuid.UUID, target: uuid.UUID) -&gt; bool:\n    \"\"\"Remove an edge, severing the relationship between two nodes\n\n    Note: This is a directional operation. It only removes the edge going\n    from source to target, not from target to source.\n    \"\"\"\n    async with self._postgres.callproc(\n        'pgraf.delete_edge', {'source': source, 'target': target}\n    ) as cursor:\n        result: dict[str, int] = await cursor.fetchone()  # type: ignore\n        return result['count'] == 1\n</code></pre>"},{"location":"api/graph/#pgraf.graph.PGraf.delete_node","title":"<code>delete_node(node_id)</code>  <code>async</code>","text":"<p>Retrieve a node by ID</p> Source code in <code>pgraf/graph.py</code> <pre><code>async def delete_node(self, node_id: uuid.UUID) -&gt; bool:\n    \"\"\"Retrieve a node by ID\"\"\"\n    async with self._postgres.callproc(\n        'pgraf.delete_node', {'id': node_id}\n    ) as cursor:\n        result: dict[str, int] = await cursor.fetchone()  # type: ignore\n        return result['count'] == 1\n</code></pre>"},{"location":"api/graph/#pgraf.graph.PGraf.get_edge","title":"<code>get_edge(source, target)</code>  <code>async</code>","text":"<p>Retrieve an edge from source to target</p> <p>Note: This is a directional operation. It only retrieves the edge going from source to target, not from target to source.</p> Source code in <code>pgraf/graph.py</code> <pre><code>async def get_edge(\n    self, source: uuid.UUID, target: uuid.UUID\n) -&gt; models.Edge | None:\n    \"\"\"Retrieve an edge from source to target\n\n    Note: This is a directional operation. It only retrieves the edge going\n    from source to target, not from target to source.\n    \"\"\"\n    async with self._postgres.callproc(\n        'pgraf.get_edge', {'source': source, 'target': target}, models.Edge\n    ) as cursor:\n        if cursor.rowcount == 0:\n            return None\n        return await cursor.fetchone()  # type: ignore\n</code></pre>"},{"location":"api/graph/#pgraf.graph.PGraf.get_edge_labels","title":"<code>get_edge_labels()</code>  <code>async</code>","text":"<p>Retrieve all of the edge labels in the graph</p> Source code in <code>pgraf/graph.py</code> <pre><code>async def get_edge_labels(self) -&gt; list[str]:\n    \"\"\"Retrieve all of the edge labels in the graph\"\"\"\n    return await self._get_labels('edges')\n</code></pre>"},{"location":"api/graph/#pgraf.graph.PGraf.get_edge_properties","title":"<code>get_edge_properties()</code>  <code>async</code>","text":"<p>Retrieve all of the edge property names in the graph</p> Source code in <code>pgraf/graph.py</code> <pre><code>async def get_edge_properties(self) -&gt; list[str]:\n    \"\"\"Retrieve all of the edge property names in the graph\"\"\"\n    return await self._get_properties('edges')\n</code></pre>"},{"location":"api/graph/#pgraf.graph.PGraf.get_edges","title":"<code>get_edges(labels=None, properties=None)</code>  <code>async</code>","text":"<p>Get edges by criteria</p> Source code in <code>pgraf/graph.py</code> <pre><code>async def get_edges(\n    self, labels: list[str] | None = None, properties: dict | None = None\n) -&gt; typing.AsyncGenerator[models.Edge, None]:\n    \"\"\"Get edges by criteria\"\"\"\n    statement, parameters = self._build_statement(\n        queries.GET_EDGES, labels, properties\n    )\n    async with self._postgres.execute(\n        statement, parameters, models.Edge\n    ) as cursor:\n        async for row in cursor:\n            yield models.Edge.model_validate(row)\n</code></pre>"},{"location":"api/graph/#pgraf.graph.PGraf.get_node","title":"<code>get_node(node_id)</code>  <code>async</code>","text":"<p>Retrieve a node by ID</p> Source code in <code>pgraf/graph.py</code> <pre><code>async def get_node(self, node_id: uuid.UUID | None) -&gt; models.Node | None:\n    \"\"\"Retrieve a node by ID\"\"\"\n    async with self._postgres.callproc(\n        'pgraf.get_node', {'id': node_id}, models.Node\n    ) as cursor:\n        if cursor.rowcount == 1:\n            return await cursor.fetchone()  # type: ignore\n        return None\n</code></pre>"},{"location":"api/graph/#pgraf.graph.PGraf.get_node_labels","title":"<code>get_node_labels()</code>  <code>async</code>","text":"<p>Retrieve all of the node types in the graph</p> Source code in <code>pgraf/graph.py</code> <pre><code>async def get_node_labels(self) -&gt; list[str]:\n    \"\"\"Retrieve all of the node types in the graph\"\"\"\n    return await self._get_labels('nodes')\n</code></pre>"},{"location":"api/graph/#pgraf.graph.PGraf.get_node_properties","title":"<code>get_node_properties()</code>  <code>async</code>","text":"<p>Retrieve the distincty property names across all nodes</p> Source code in <code>pgraf/graph.py</code> <pre><code>async def get_node_properties(self) -&gt; list[str]:\n    \"\"\"Retrieve the distincty property names across all nodes\"\"\"\n    return await self._get_properties('nodes')\n</code></pre>"},{"location":"api/graph/#pgraf.graph.PGraf.get_nodes","title":"<code>get_nodes(labels=None, properties=None)</code>  <code>async</code>","text":"<p>Get all nodes matching the criteria</p> Source code in <code>pgraf/graph.py</code> <pre><code>async def get_nodes(\n    self, labels: list[str] | None = None, properties: dict | None = None\n) -&gt; typing.AsyncGenerator[models.Node, None]:\n    \"\"\"Get all nodes matching the criteria\"\"\"\n    statement, parameters = self._build_statement(\n        queries.GET_NODES, labels, properties\n    )\n    async with self._postgres.execute(\n        statement, parameters, models.Node\n    ) as cursor:\n        async for row in cursor:\n            yield models.Node.model_validate(row)\n</code></pre>"},{"location":"api/graph/#pgraf.graph.PGraf.initialize","title":"<code>initialize()</code>  <code>async</code>","text":"<p>Ensure the database is connected and ready to go.</p> Source code in <code>pgraf/graph.py</code> <pre><code>async def initialize(self) -&gt; None:\n    \"\"\"Ensure the database is connected and ready to go.\"\"\"\n    await self._postgres.initialize()\n</code></pre>"},{"location":"api/graph/#pgraf.graph.PGraf.search","title":"<code>search(query, labels=None, properties=None, similarity_threshold=0.1, limit=10, offset=0)</code>  <code>async</code>","text":"<p>Search the content nodes in the graph, optionally filtering by properties, node types, and the edges labels.</p> Source code in <code>pgraf/graph.py</code> <pre><code>async def search(\n    self,\n    query: str,\n    labels: list[str] | None = None,\n    properties: dict | None = None,\n    similarity_threshold: float = 0.1,\n    limit: int = 10,\n    offset: int = 0,\n) -&gt; list[models.SearchResult]:\n    \"\"\"Search the content nodes in the graph, optionally filtering by\n    properties, node types, and the edges labels.\n\n    \"\"\"\n    vector = self._embeddings.get(query)\n    if len(vector) &gt; 1:\n        LOGGER.warning(\n            'Search text embeddings returned %i vector arrays', len(vector)\n        )\n    async with self._postgres.callproc(\n        'pgraf.search',\n        {\n            'query': query,\n            'labels': labels,\n            'properties': json.Jsonb(properties) if properties else None,\n            'embeddings': vector[0],\n            'similarity': similarity_threshold,\n            'limit': limit,\n            'offset': offset,\n        },\n        models.SearchResult,\n    ) as cursor:\n        results: list[models.SearchResult] = await cursor.fetchall()  # type: ignore\n        return results\n</code></pre>"},{"location":"api/graph/#pgraf.graph.PGraf.traverse","title":"<code>traverse(start_node, node_labels=None, edge_labels=None, direction='outgoing', max_depth=5, limit=25)</code>  <code>async</code>","text":"<p>Traverse the graph from a starting node</p> Source code in <code>pgraf/graph.py</code> <pre><code>async def traverse(\n    self,\n    start_node: uuid.UUID,\n    node_labels: list[str] | None = None,\n    edge_labels: list[str] | None = None,\n    direction: str = 'outgoing',\n    max_depth: int = 5,\n    limit: int = 25,\n) -&gt; list[tuple[models.Node, models.Edge | None]]:\n    \"\"\"Traverse the graph from a starting node\"\"\"\n    results: list[tuple[models.Node, models.Edge | None]] = []\n    visited_nodes = set()  # Track visited nodes to avoid duplicates\n\n    # Recursive helper function to implement depth-first traversal\n    async def traverse_recursive(node_id, current_depth=0, path_edge=None):\n        # Check the limit\n        if len(results) &gt;= limit:\n            return\n\n        # Check max depth\n        if current_depth &gt; max_depth:\n            return\n\n        # Check if we've visited this node\n        if node_id in visited_nodes:\n            return\n\n        # Mark this node as visited\n        visited_nodes.add(node_id)\n\n        # Get the current node\n        current_node = await self.get_node(node_id)\n        if not current_node:\n            return\n\n        # Apply node label filtering\n        if node_labels and not any(\n            label in current_node.labels for label in node_labels\n        ):\n            # Only filter at depth &gt; 0 to ensure starting node is included\n            if current_depth &gt; 0:\n                return\n\n        # Add this node to results\n        results.append((current_node, path_edge))\n\n        if current_depth &gt;= max_depth:\n            return\n\n        # Build SQL query based on direction\n        if direction == 'outgoing':\n            query = sql.SQL(\n                'SELECT * FROM pgraf.edges WHERE source = %(node_id)s'\n            )\n        elif direction == 'incoming':\n            query = sql.SQL(\n                'SELECT * FROM pgraf.edges WHERE target = %(node_id)s'\n            )\n        else:  # both\n            query = sql.SQL(\n                \"\"\"\\\n                SELECT *\n                  FROM pgraf.edges\n                 WHERE source = %(node_id)s\n                    OR target = %(node_id)s\n                \"\"\"\n            )\n\n        # Get all edges connected to this node\n        async with self._postgres.execute(\n            query, {'node_id': node_id}\n        ) as cursor:\n            edges = await cursor.fetchall()\n\n            # Process each edge\n            for edge_row in edges:\n                # Skip edges that don't match filter criteria\n                if edge_labels and not any(\n                    label in edge_row['labels'] for label in edge_labels\n                ):\n                    continue\n\n                # Create the edge model\n                edge = models.Edge(\n                    source=edge_row['source'],\n                    target=edge_row['target'],\n                    labels=edge_row['labels'],\n                    properties=edge_row['properties'],\n                )\n\n                # Determine the next node ID based on direction\n                next_id = edge_row['target']\n                if direction == 'incoming' or (\n                    direction == 'both' and edge_row['target'] == node_id\n                ):\n                    next_id = edge_row['source']\n\n                # Skip if it's the current node\n                if next_id == node_id:\n                    continue\n\n                # Recursively traverse\n                await traverse_recursive(next_id, current_depth + 1, edge)\n\n                # Check if limit reached\n                if len(results) &gt;= limit:\n                    return\n\n    await traverse_recursive(start_node)\n    LOGGER.debug(\n        'Traverse results: %s items, visited %s nodes',\n        len(results),\n        len(visited_nodes),\n    )\n    return results\n</code></pre>"},{"location":"api/graph/#pgraf.graph.PGraf.update_edge","title":"<code>update_edge(edge)</code>  <code>async</code>","text":"<p>Update an edge</p> Source code in <code>pgraf/graph.py</code> <pre><code>async def update_edge(self, edge: models.Edge) -&gt; models.Edge:\n    \"\"\"Update an edge\"\"\"\n    async with self._postgres.callproc(\n        'pgraf.update_edge', edge, models.Edge\n    ) as cursor:\n        return await cursor.fetchone()  # type: ignore\n</code></pre>"},{"location":"api/graph/#pgraf.graph.PGraf.update_node","title":"<code>update_node(node)</code>  <code>async</code>","text":"<p>Update a node</p> Source code in <code>pgraf/graph.py</code> <pre><code>async def update_node(self, node: models.Node) -&gt; models.Node:\n    \"\"\"Update a node\"\"\"\n    async with self._postgres.callproc(\n        'pgraf.update_node', node, models.Node\n    ) as cursor:\n        result: models.Node = await cursor.fetchone()  # type: ignore\n    if result.content is not None:\n        await self._add_embeddings(result.id, result.content)\n    return result\n</code></pre>"},{"location":"api/models/","title":"Models","text":""},{"location":"api/models/#pgraf.models","title":"<code>pgraf.models</code>","text":""},{"location":"api/models/#pgraf.models.Edge","title":"<code>Edge</code>","text":"<p>               Bases: <code>_GraphModel</code></p> <p>An edge represents the relationship between two nodes</p> Source code in <code>pgraf/models.py</code> <pre><code>class Edge(_GraphModel):\n    \"\"\"An edge represents the relationship between two nodes\"\"\"\n\n    source: uuid.UUID\n    target: uuid.UUID\n</code></pre>"},{"location":"api/models/#pgraf.models.Embedding","title":"<code>Embedding</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>An embedding is a fixed-length vector of floating-point numbers that represents the semantic meaning of a document chunk in a high-dimensional space, enabling similarity search operations for retrieving contextually relevant information in RAG systems.</p> Source code in <code>pgraf/models.py</code> <pre><code>class Embedding(pydantic.BaseModel):\n    \"\"\"An embedding is a fixed-length vector of floating-point numbers that\n    represents the semantic meaning of a document chunk in a high-dimensional\n    space, enabling similarity search operations for retrieving contextually\n    relevant information in RAG systems.\"\"\"\n\n    node: uuid.UUID\n    chunk: int\n    value: list[float]\n\n    @pydantic.field_validator('value')\n    @classmethod\n    def validate_value_length(cls, value: list[float]) -&gt; list[float]:\n        \"\"\"Validate that the embedding value has exactly 384 dimensions.\"\"\"\n        if len(value) != 384:\n            raise ValueError(\n                f'Value must have exactly 384 dimensions, got {len(value)}'\n            )\n        return value\n</code></pre>"},{"location":"api/models/#pgraf.models.Embedding.validate_value_length","title":"<code>validate_value_length(value)</code>  <code>classmethod</code>","text":"<p>Validate that the embedding value has exactly 384 dimensions.</p> Source code in <code>pgraf/models.py</code> <pre><code>@pydantic.field_validator('value')\n@classmethod\ndef validate_value_length(cls, value: list[float]) -&gt; list[float]:\n    \"\"\"Validate that the embedding value has exactly 384 dimensions.\"\"\"\n    if len(value) != 384:\n        raise ValueError(\n            f'Value must have exactly 384 dimensions, got {len(value)}'\n        )\n    return value\n</code></pre>"},{"location":"api/models/#pgraf.models.Node","title":"<code>Node</code>","text":"<p>               Bases: <code>_GraphModel</code></p> <p>A node represents an entity or object within the graph model.</p> Source code in <code>pgraf/models.py</code> <pre><code>class Node(_GraphModel):\n    \"\"\"A node represents an entity or object within the graph model.\"\"\"\n\n    id: uuid.UUID = pydantic.Field(default_factory=utils.uuidv7)\n    mimetype: str | None = None\n    content: str | None = None\n</code></pre>"},{"location":"api/models/#pgraf.models.SearchResult","title":"<code>SearchResult</code>","text":"<p>               Bases: <code>Node</code></p> <p>Used for the return results of a search</p> Source code in <code>pgraf/models.py</code> <pre><code>class SearchResult(Node):\n    \"\"\"Used for the return results of a search\"\"\"\n\n    similarity: float\n</code></pre>"},{"location":"api/postgres/","title":"Postgres","text":""},{"location":"api/postgres/#pgraf.postgres","title":"<code>pgraf.postgres</code>","text":""},{"location":"api/postgres/#pgraf.postgres.Postgres","title":"<code>Postgres</code>","text":"Source code in <code>pgraf/postgres.py</code> <pre><code>class Postgres:\n    def __init__(\n        self,\n        url: pydantic.PostgresDsn,\n        pool_min_size: int = 1,\n        pool_max_size: int = 10,\n    ) -&gt; None:\n        self._lock = asyncio.Lock()\n        self._pool: psycopg_pool.AsyncConnectionPool | None = (\n            psycopg_pool.AsyncConnectionPool(\n                str(url),\n                kwargs={'autocommit': True, 'row_factory': rows.dict_row},\n                max_size=pool_max_size,\n                min_size=pool_min_size,\n                open=False,\n                configure=self._configure_vector,\n            )\n        )\n        self._url = str(url)\n\n    async def initialize(self) -&gt; None:\n        \"\"\"Initialize the connection pool\"\"\"\n        async with self._lock:\n            await self._open_pool()\n\n    async def aclose(self) -&gt; None:\n        \"\"\"Close the connection pool, returns False if the pool\n        is already closed.\n\n        \"\"\"\n        async with self._lock:\n            if self._pool and not self._pool.closed:\n                LOGGER.debug('Closing connection pool')\n                await self._pool.close()\n            self._pool = None\n\n    @contextlib.asynccontextmanager\n    async def callproc(\n        self,\n        proc_name: str,\n        parameters: dict | pydantic.BaseModel,\n        row_class: type[pydantic.BaseModel] | None = None,\n    ) -&gt; abc.AsyncGenerator[AsyncCursor]:\n        \"\"\"Call a stored procedure\"\"\"\n        statement = await self._callproc_statement(proc_name)\n        if hasattr(parameters, 'model_dump'):\n            parameters = parameters.model_dump()\n        async with self.execute(statement, parameters, row_class) as cursor:\n            yield cursor\n\n    @contextlib.asynccontextmanager\n    async def cursor(\n        self, row_class: type[pydantic.BaseModel] | None = None\n    ) -&gt; abc.AsyncGenerator[AsyncCursor]:\n        \"\"\"Get a cursor for Postgres.\"\"\"\n        if not self._pool:\n            raise RuntimeError('Postgres instance already closed')\n        elif self._pool.closed:\n            await self._open_pool()\n        async with self._pool.connection() as conn:\n            async with conn.cursor(\n                row_factory=rows.class_row(row_class)\n                if row_class\n                else rows.dict_row\n            ) as cursor:\n                yield cursor\n\n    @contextlib.asynccontextmanager\n    async def execute(\n        self,\n        query: str | sql.Composable,\n        parameters: dict | None = None,\n        row_class: type[pydantic.BaseModel] | None = None,\n    ) -&gt; typing.AsyncIterator[AsyncCursor]:\n        \"\"\"Wrapper context manager for making executing queries easier.\"\"\"\n        async with self.cursor(row_class) as cursor:\n            if isinstance(query, sql.Composable):\n                query = query.as_string(cursor)\n            composed = re.sub(r'\\s+', ' ', query).encode('utf-8')\n            try:\n                await cursor.execute(composed, parameters or {})\n                yield cursor\n            except psycopg.DatabaseError as err:\n                raise errors.DatabaseError(str(err)) from err\n\n    async def _open_pool(self) -&gt; None:\n        \"\"\"Open the connection pool, returns False if the pool\n        is already open.\n\n        \"\"\"\n        if self._pool and self._pool.closed:\n            LOGGER.debug(\n                'Opening connection pool to %s', utils.sanitize(self._url)\n            )\n            await self._pool.open(True, timeout=3.0)\n            LOGGER.debug('Connection pool opened')\n\n    async def _callproc_columns(\n        self, proc_name: str, schema_name: str = 'public'\n    ) -&gt; typing.AsyncGenerator[tuple[str, str | None], None]:\n        \"\"\"Get the columns for a stored procedure in order, expects the\n        convention of _in for an input column name\n\n        \"\"\"\n        async with self.execute(\n            queries.PROC_NAMES,\n            {'proc_name': proc_name, 'schema_name': schema_name},\n        ) as cursor:\n            if not cursor.rowcount:\n                raise errors.DatabaseError(\n                    f'Failed to fetch stored procedure: '\n                    f'{schema_name}.{proc_name}'\n                )\n            result: list[dict] = await cursor.fetchall()  # type: ignore\n            for row in result:\n                if row['arg_type'] == 'vector':\n                    yield row['arg_name'], None\n                else:\n                    yield row['arg_name'], row['arg_type']\n\n    async def _callproc_statement(self, proc_name: str) -&gt; sql.Composed:\n        \"\"\"Generate the statement to invoke the stored procedure\"\"\"\n        schema = 'public'\n        if '.' in proc_name:\n            schema, proc_name = proc_name.split('.')\n        statement: list[str | sql.Composable] = [\n            sql.SQL('SELECT * FROM '),\n            sql.Identifier(schema),\n            sql.SQL('.'),\n            sql.Identifier(proc_name),\n            sql.SQL('('),\n        ]\n        async for name, col_type in self._callproc_columns(proc_name, schema):\n            if col_type is None:\n                statement.append(sql.Placeholder(name))\n            else:\n                statement.append(\n                    sql.Placeholder(name) + sql.SQL('::') + sql.SQL(col_type)  # type: ignore\n                )\n            statement.append(sql.SQL(', '))\n        if len(statement) &gt; 5:  # Strip the last ,\n            statement = statement[:-1]\n        statement.append(sql.SQL(')'))\n        LOGGER.debug('callproc: %s', sql.Composed(statement).as_string())\n        return sql.Composed(statement)\n\n    @staticmethod\n    async def _configure_vector(conn: psycopg.AsyncConnection) -&gt; None:\n        await register_vector_async(conn)\n</code></pre>"},{"location":"api/postgres/#pgraf.postgres.Postgres.aclose","title":"<code>aclose()</code>  <code>async</code>","text":"<p>Close the connection pool, returns False if the pool is already closed.</p> Source code in <code>pgraf/postgres.py</code> <pre><code>async def aclose(self) -&gt; None:\n    \"\"\"Close the connection pool, returns False if the pool\n    is already closed.\n\n    \"\"\"\n    async with self._lock:\n        if self._pool and not self._pool.closed:\n            LOGGER.debug('Closing connection pool')\n            await self._pool.close()\n        self._pool = None\n</code></pre>"},{"location":"api/postgres/#pgraf.postgres.Postgres.callproc","title":"<code>callproc(proc_name, parameters, row_class=None)</code>  <code>async</code>","text":"<p>Call a stored procedure</p> Source code in <code>pgraf/postgres.py</code> <pre><code>@contextlib.asynccontextmanager\nasync def callproc(\n    self,\n    proc_name: str,\n    parameters: dict | pydantic.BaseModel,\n    row_class: type[pydantic.BaseModel] | None = None,\n) -&gt; abc.AsyncGenerator[AsyncCursor]:\n    \"\"\"Call a stored procedure\"\"\"\n    statement = await self._callproc_statement(proc_name)\n    if hasattr(parameters, 'model_dump'):\n        parameters = parameters.model_dump()\n    async with self.execute(statement, parameters, row_class) as cursor:\n        yield cursor\n</code></pre>"},{"location":"api/postgres/#pgraf.postgres.Postgres.cursor","title":"<code>cursor(row_class=None)</code>  <code>async</code>","text":"<p>Get a cursor for Postgres.</p> Source code in <code>pgraf/postgres.py</code> <pre><code>@contextlib.asynccontextmanager\nasync def cursor(\n    self, row_class: type[pydantic.BaseModel] | None = None\n) -&gt; abc.AsyncGenerator[AsyncCursor]:\n    \"\"\"Get a cursor for Postgres.\"\"\"\n    if not self._pool:\n        raise RuntimeError('Postgres instance already closed')\n    elif self._pool.closed:\n        await self._open_pool()\n    async with self._pool.connection() as conn:\n        async with conn.cursor(\n            row_factory=rows.class_row(row_class)\n            if row_class\n            else rows.dict_row\n        ) as cursor:\n            yield cursor\n</code></pre>"},{"location":"api/postgres/#pgraf.postgres.Postgres.execute","title":"<code>execute(query, parameters=None, row_class=None)</code>  <code>async</code>","text":"<p>Wrapper context manager for making executing queries easier.</p> Source code in <code>pgraf/postgres.py</code> <pre><code>@contextlib.asynccontextmanager\nasync def execute(\n    self,\n    query: str | sql.Composable,\n    parameters: dict | None = None,\n    row_class: type[pydantic.BaseModel] | None = None,\n) -&gt; typing.AsyncIterator[AsyncCursor]:\n    \"\"\"Wrapper context manager for making executing queries easier.\"\"\"\n    async with self.cursor(row_class) as cursor:\n        if isinstance(query, sql.Composable):\n            query = query.as_string(cursor)\n        composed = re.sub(r'\\s+', ' ', query).encode('utf-8')\n        try:\n            await cursor.execute(composed, parameters or {})\n            yield cursor\n        except psycopg.DatabaseError as err:\n            raise errors.DatabaseError(str(err)) from err\n</code></pre>"},{"location":"api/postgres/#pgraf.postgres.Postgres.initialize","title":"<code>initialize()</code>  <code>async</code>","text":"<p>Initialize the connection pool</p> Source code in <code>pgraf/postgres.py</code> <pre><code>async def initialize(self) -&gt; None:\n    \"\"\"Initialize the connection pool\"\"\"\n    async with self._lock:\n        await self._open_pool()\n</code></pre>"},{"location":"api/queries/","title":"Queries","text":""},{"location":"api/queries/#pgraf.queries","title":"<code>pgraf.queries</code>","text":""},{"location":"api/queries/#pgraf.queries--sql-queries","title":"SQL Queries","text":""},{"location":"api/utils/","title":"Utils","text":""},{"location":"api/utils/#pgraf.utils","title":"<code>pgraf.utils</code>","text":""},{"location":"api/utils/#pgraf.utils.current_timestamp","title":"<code>current_timestamp()</code>","text":"<p>Return the current timestamp</p> Source code in <code>pgraf/utils.py</code> <pre><code>def current_timestamp() -&gt; datetime.datetime:\n    \"\"\"Return the current timestamp\"\"\"\n    return datetime.datetime.now(tz=datetime.UTC)\n</code></pre>"},{"location":"api/utils/#pgraf.utils.sanitize","title":"<code>sanitize(url)</code>","text":"<p>Mask passwords in URLs for security.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str | AnyUrl | PostgresDsn</code> <p>Input string that may contain URLs with passwords</p> required <p>Returns:</p> Type Description <code>str</code> <p>Text with passwords in URLs replaced with asterisks</p> Source code in <code>pgraf/utils.py</code> <pre><code>def sanitize(url: str | pydantic.AnyUrl | pydantic.PostgresDsn) -&gt; str:\n    \"\"\"Mask passwords in URLs for security.\n\n    Args:\n        url: Input string that may contain URLs with passwords\n\n    Returns:\n        Text with passwords in URLs replaced with asterisks\n\n    \"\"\"\n    pattern = re.compile(r'(\\w+?://[^:@]+:)([^@]+)(@)')\n    return pattern.sub(r'\\1******\\3', str(url))\n</code></pre>"},{"location":"api/utils/#pgraf.utils.uuidv7","title":"<code>uuidv7()</code>","text":"<p>Return a UUIDv7 value as a UUID object</p> Source code in <code>pgraf/utils.py</code> <pre><code>def uuidv7() -&gt; uuid.UUID:\n    \"\"\"Return a UUIDv7 value as a UUID object\"\"\"\n    return uuid.UUID(str(uuid_utils.uuid7()))\n</code></pre>"}]}